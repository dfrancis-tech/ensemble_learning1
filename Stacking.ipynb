{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db99be8-8acb-4bb9-9b3b-79d28e0aafed",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "Stacking is an ensemble method that creates a strong metamodel trained on the predictions of several independent base models.\n",
    "\n",
    "- Comparison with Boosting and Bagging:\n",
    "    * Training Data:\n",
    "        - Stacking uses the full training set for both base models and the metamodel.\n",
    "        - Boosting and bagging use sampling techniques to create training sets for their base models.\n",
    "    * Base Models:\n",
    "        - In stacking, base models can be different algorithms (e.g., logistic regression, random forest), leveraging their unique strengths.\n",
    "        - Boosting and bagging often use a large number of similar base models (sometimes hundreds).\n",
    "    * Metamodel Complexity:\n",
    "        - Stacking builds a more complex metamodel that learns from the base model predictions.\n",
    "        - Boosting and bagging typically use naive metamodels that average or vote on predictions.\n",
    "- Functionality of the Metamodel:\n",
    "The metamodel can prioritize and weight the contributions of different base models based on their unique insights.\n",
    "Additional data can be incorporated into the metamodel alongside base model predictions, depending on the problem.\n",
    "- Advantages of Stacking:\n",
    "Utilizing different algorithms allows for diverse insights from the training data.\n",
    "The framework combines outputs from various models, enhancing predictive power.\n",
    "\n",
    "- Stacking starts with the full training set, generating predictions from different base models that are then fed into a metamodel.\n",
    "The metamodel is trained to produce the final prediction, learning how to weight the insights from the base models effectively.\n",
    "This structure allows stacking to be a powerful framework in ensemble learning, capturing a wider range of information for improved predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52315b8a-d304-4024-9030-444723097eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb2250-5c46-40d2-8d77-499119b85696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the hyperparameters\n",
    "\n",
    "estimators = [{'gb', GradietBoost\n",
    "StackingClassifier().get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
